---
layout: papers
title:  "TASK2VEC: Task Embedding for Meta-Learning"
subtitle: "reading papers"
date: 2023-3-24
categories: ["papers"]
feature_image: /assets/img/image_1679647634163_0.png
sitemap:
  priority: 0.5
publish: True
---
## どんなものか
- 視覚的分類タスクのベクトル表現を提供し、タスクの性質とその関係性を推論するために利用できることを示した
	- タスクをプローブネットワークに入力しモデルのフィルターパラメータの対角フィッシャー情報行列を計算することで、この表現がタスクの難易度、入力ドメインの特徴などタスクを表現するベクトルとなることを示した
<!--more-->
- ![image.png](/assets/img/image_1679647634163_0.png)
	- 大規模なデータセットの部分集合の埋め込み
	- 左、iNaturalist, CUB-200, iMaterialistデータセットから抽出したタスクの埋め込みをT-SNEで可視化したもの
	- 右、同じタスクのドメイン埋め込みのT-SNE可視化（平均特徴量を使用）

## 先行研究と比べて
- タスクとドメインの埋め込みについて、ドメインによって区別されるタスクは単純に画像統計の観点から理解できるが自然画像のようなドメインが同じでタスクが違うような場合に既存手法では計算量がかかる手法しかなかった

## 技術や手法のポイント
- **フィッシャー情報によるタスクの埋め込み**
- プローブネットワークを用いたVECの埋め込み
	- ImageNetで事前学習済みモデルをプローブネットワークとする
	- CNNによる特徴マップ全ての値を使うのは大きすぎるので、対角の項目のみを用いてかつ同じフィルタの重みについてフィッシャー情報を平均化する

## 検証方法
- 埋め込みの質的特性とメタ学習タスクでの性能の両方をテストすることで検証する
- プローブネットワークにはResNet-34を使用
- タスクのコレクションにはiNaturalist、CUB-200、iMaterialist、DeepFashionの4つのデータセットから抽出したタスクを用いる
- タスク埋め込みの結果
	- iNaturalistの分類学的距離を定性的に反映する
	- ![image.png](/assets/img/image_1679650490096_0.png)
	- 左はタスク類似度行列を階層的クラスタリングで並べたもの
		- タスクの類似性によって作成されたデンドログラムは分類学的なクラスタ（カラーバー）と一致していることが読み取れる
	- 中はiNaturalistとCUBから抽出したタスクについてタスク間のコサイン距離とその分類学的距離を比較する
	- 右はタスクの埋め込みの原点からのL1ノルムとタスクで得られたテスト誤差の相関
	-
	- タスク埋め込みはタスクの難易度を符号化する
	- ![image.png](/assets/img/image_1679650902944_0.png)
	- タスクの埋め込みのノルム（原点からの距離？）とエキスパートモデルの性能を比較したもの
- モデル選択
	- タスクが与えられたときそのタスクの分類性能を最大化するエキスパートな特徴抽出器を選択したい
	- ![image.png](/assets/img/image_1679651171543_0.png)
	- 2つのメタ学習タスクにおいて最適なエキスパートを網羅的に探索することで得られる平均最適誤差と、より安価なモデル選択方法を用いた場合の相対誤差の増加

## 議論
-
