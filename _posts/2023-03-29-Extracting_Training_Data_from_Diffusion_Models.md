---
layout: papers
title:  "Extracting Training Data from Diffusion Models"
subtitle: "reading papers"
date: 2023-3-27
categories: ["papers"]
feature_image: /assets/img/image_1679908690396_0.png
sitemap:
  priority: 0.7
publish: True
---
## どんなものか
- 拡散モデルによる生成モデルが学習データを記憶しておりそれを取り出すことができることを示す
<!--more-->
- ![image.png](/assets/img/image_1679908690396_0.png){:height 247, :width 375}
	- 左は訓練データ、右は生成されたデータ

## 先行研究と比べて
- 訓練データを再構成する手法はいくつかあったが、拡散モデルに焦点を当てた論文はなかった
- また拡散モデルのプライバシーに関する研究もされておりそこでは訓練データを生成できるいくつかの例を示している
	- しかし生成された画像の意味的類似性を訓練データと比較する「スタイルコピー」に焦点を当てている
	- 対して本論文ではより限定的な暗記という概念の下での訓練データ再構成に焦点を当てる

## 技術や手法のポイント
- Stable Diffusionのモデルを使用するが訓練データが1億6000万枚あり全探索していると時間がかかるので、CLIPにより特徴量を(512,512,3) -> (512)として比較を行う
- ブラックボックス攻撃
	- ある条件下でたくさん画像を生成 -> 似た画像が生成されたら訓練データである確率たかそうだよね

## 検証方法
- 実際に行った結果
- ブラックボックス攻撃
	- 訓練データセットから重複の多い35万例を選択しこれらのプロンプトごとに500枚の候補画像を生成し攻撃を行った
	- ![image.png](/assets/img/image_1679909645504_0.png)
	- 上段がオリジナル画像、下段が生成画像

- GANとDiffusionでのプライバシー性の比較
	- GANのモデルに対してLiRA攻撃を行いDiffusionモデルと比較した
	- GANの方がプライバシー性は高かった
		- 訓練データ再構成できた枚数がDiffusionの方が2倍くらいであった
	- DiffusionとGANのどちらについても同じ画像が記憶されていることが多かった

## 議論
- 全然載せてないけど、CIFAR-10による多くの実験がなされていて凄い
