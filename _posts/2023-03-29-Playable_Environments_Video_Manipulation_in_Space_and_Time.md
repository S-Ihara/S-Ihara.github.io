---
layout: papers
title:  "Playable Environments: Video Manipulation in Space and Time"
subtitle: "reading papers"
date: 2023-3-28
categories: ["papers"]
feature_image: /assets/img/image_1679986024954_0.png
sitemap:
  priority: 0.8
publish: True
---
## どんなものか
- インタラクティブな映像生成と操作のための新しい表現であるPlayable Environmentsを提案した
- 1枚の初期フレームを与えると、そのシーンからインタラクティブに操作可能な環境を作り出す
<!--more-->
- ![image.png](/assets/img/image_1679986024954_0.png)

## 先行研究と比べて
- 新しいシーンの合成やvolumetric renderingは静的なシーンの再レンダリング手法としてあったが、動的な環境を扱うのが難しくユーザーとの対話ができなかった
- Playableなビデオ生成の研究はあったが制御可能な単一のオブジェクトのみを想定しているのに対し、本論文はカメラの動きや複雑な3Dインタラクションもモデル化し様々なオブジェクトの外観をサポートする

## 技術や手法のポイント
- 提案フレームワーク
	- ![image.png](/assets/img/image_1679986845409_0.png)
	- エンコーダーEはシーン内のすべてのオブジェクトについて環境状態を抽出する
	- 合成モジュール(Synthesis Module)はNeRFのようなアーキテクチャに従って入力フレームを再構成しカメラ操作を可能にする
	- アクションモジュールは状態のダイナミクスを離散的なアクションラベルでエンコードするように学習する
- Synthesis Module
	- ![image.png](/assets/img/image_1679987146945_0.png)
	- カメラポーズと状態から入力画像を再構築することを目的としたモジュール
	- オブジェクトごとに状態が渡されそれらをNeRFによるレンダリングで1つの状態として扱う
- Action Module
	- ![image.png](/assets/img/image_1679987467818_0.png)
	- 時刻tとt+1の状態が与えられると行動ネットワークAは離散的な行動ラベルaと行動変数vtを予測し、ダイナミクスネットワークRを組み合わせて新しい環境状態st+1を推定する
	- 環境に存在する非決定性のため時間tに実行されたatの特定の変動を記述するアクション変動埋め込みvtを抽出する
	- RにはLSTMを用いる
- 学習
	- エンコーダーと合成モジュールを収束するまで訓練し、次にアクションモジュールを訓練する
	- エンコーダーと合成モジュールの損失関数は画像とのLPIPSとMSEで行う
	- アクションモジュールの損失関数
		- 入力stと再構成されたs^tに対してそれぞれアクション確率pt, p^tの内部推定値を生成しこれら2つの分布間の相互情報の最大化
		- J個の画像ペアを含むバッチからオブジェクトの動き $\Delta_j$ と各アクションの平均オブジェクトモーション
			-
$$\forall k \in \{ 1,\ldots,K \}, \mu_k = \frac{\sum_{j=1}^{J} p_{jk} \Delta_j}{\sum_{j=1}^{J} p_{jk}}$$			- ここでp_jkは画像ペアjがアクションkに割り当てられる確率
			- そして各アクションの動き $\Delta_j$ と平均の動きの間のMSEを最小化させる
			-
$$\mathcal{L}_{\Delta} = \frac{1}{\text{Var}(\Delta)} \sum_{j=1}^{J} \sum_{k=1}^{K} p_{jk} || \Delta_j - _mu_k ||^2_2$$			- ここでVar(・)は正規化係数
		- 時間的な識別器Dを導入しGANみたいな損失を構成
		- 以上をまとめた損失を損失関数として使用

## 検証方法
- 学習データセット
	- Minecraftのデータセット
	- 実世界上でのテニス映像のデータセット
- 既存手法との比較
	- 再構成シーンの評価
	- ![image.png](/assets/img/image_1679989738084_0.png)
	- Playabilityの評価とカメラ制御の評価
	- ![image.png](/assets/img/image_1679989798604_0.png)
- 定性的な評価
	- 獲得された行動空間の解析
	- ![image.png](/assets/img/image_1679989890833_0.png){:height 299, :width 505}
	- 各色は学習したアクションを表し、各矢印はそれぞれのアクションを初期プレイヤーに6回適用した場合の効果を示す
	- 床のオーバーレイは各アクションの適用後に可能なエンディングポジションの分布を示す

## 議論
- アイデアは面白そうに感じた